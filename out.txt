             GGG   U   U  I  DDDD   EEEE
            G   G  U   U  I  D   D  E
            G      U   U  I  D   D  E
            G  GG  U   U  I  D   D  EEE
            G   G  U   U  I  D   D  E
            G   G  U   U  I  D   D  E
             GGG    UUU   I  DDDD   EEEE
   
 GUIDE Classification and Regression Trees and Forests
 Compiled with GFortran 5.2.1 on Ubuntu 15.10
 Version 23.0 (Build date: September 15, 2016)     
 Copyright (c) 1997-2016 Wei-Yin Loh. All rights reserved.
 This software is based upon work supported by the U.S. Army Research Office,
 the National Science Foundation and the National Institutes of Health.
  
 This job was started on: 10/06/16 at 14:28
  
 Classification tree
 Pruning by cross-validation
 Data description file: dsc.txt
 Training sample file: data.txt
 Missing value code: ?
 Records in data file start on line 1
 Warning: N variables changed to S
 Dependent variable is Class
 Number of records in data file: 99
 Length of longest data entry: 3
 Number of classes =  3
 Class      #Cases    Proportion
 0              33    0.33333333
 1              33    0.33333333
 2              33    0.33333333
  
 Summary information (without x variables)
 d=dependent, b=split and fit cat variable using 0-1 dummies,
 c=split-only categorical, n=split and fit numerical, f=fit-only numerical,
 s=split-only numerical, w=weight
  Column  Name              Minimum      Maximum   #Categories       #Missing
       1  SepalLength  s   4.4000E+00   7.7000E+00
       2  SepalWidth   s   2.2000E+00   4.4000E+00
       3  PetalLength  s   1.0000E+00   6.7000E+00
       4  PetalWidth   s   1.0000E-01   2.5000E+00
       5  Class        d                                     3
  
      Total  #cases w/   #missing
     #cases    miss. D  ord. vals   #X-var   #N-var   #F-var   #S-var   #B-var   #C-var
         99          0          0        0        0        0        4        0        0
 No. cases used for training: 99
  
 Univariate split highest priority
 No interaction and linear splits
 Pruning by v-fold cross-validation, with v =  10
 Selected tree is based on mean of CV estimates
 Simple node models
 Estimated priors
 Unit misclassification costs
 Split values for N and S variables based on exhaustive search
 Max number of split levels =  10
 Minimum node size =  3
  
 Pruning sequence
   Subtree     Pruned  #Terminal        True           Geometric
    number       node      nodes        alpha             mean
         0          0          5       0.0000          0.0000    
         1         14          4       0.0000          0.0000    
         2          7          3       0.0000          0.0000    
         3          3          2      0.30303         0.31782    
         4          1          1      0.33333         0.17977+309
  
 Number of SE's for pruned tree =   5.0000E-01
  
 Size and CV mean cost and SE of subtrees:
  Tree   #Tnodes  Mean Cost   SE(Mean)   BSE(Mean)  Median Cost  BSE(Median)
    0        5   6.061E-02   2.398E-02   1.636E-02   1.000E-01   3.916E-02
    1        4   6.061E-02   2.398E-02   1.636E-02   1.000E-01   3.916E-02
    2**      3   6.061E-02   2.398E-02   1.636E-02   1.000E-01   3.916E-02
    3        2   3.333E-01   4.738E-02   1.429E-02   3.000E-01   2.641E-02
    4        1   6.667E-01   4.738E-02   1.859E-02   7.000E-01   3.994E-02
  
 0-SE tree based on mean is marked with *
 0-SE tree based on median is marked with +
 Selected-SE tree based on mean using naive SE is marked with **
 Selected-SE tree based on mean using bootstrap SE is marked with --
 Selected-SE tree based on median and bootstrap SE is marked with ++
 ** tree and ++ tree are the same
  
 Following tree is based on mean CV with naive SE estimate (**).
  
 Structure of final tree. Each terminal node is marked with a T.
  
 Node cost is node misclassification cost divided by number of training cases
        Node    Total    Train    Predicted        Node    Split          Interacting
       label    cases    cases    class            cost    variables      variable
           1       99       99    0              6.667E-01 PetalLength 
           2T      33       33    0              0.000E+00 - 
           3       66       66    1              5.000E-01 PetalLength 
           6T      32       32    1              3.125E-02 - 
           7T      34       34    2              5.882E-02 PetalLength 
  
 Number of terminal nodes of final tree: 3
 Total number of nodes of final tree:    5
 Second best split variable (based on curvature test) at root node is PetalWidth
  
 Classification tree:
  
  Node 1: PetalLength <=    2.45000 or ?
    Node 2: 0
  Node 1: PetalLength >    2.45000 or ?
    Node 3: PetalLength <=    4.75000 and not ?
      Node 6: 1
    Node 3: PetalLength >    4.75000 or ?
      Node 7: 2
 
 ***************************************************************
 
  
 Node 1: Intermediate node
 A case goes into Node 2 if PetalLength <=  2.4500000E+00 or ?
 PetalLength mean =  3.7444E+00
 Class      Number  ClassPrior
 0              33     0.33333
 1              33     0.33333
 2              33     0.33333
 Number of training cases misclassified =  66
 Predicted class is 0
 ----------------------------
 Node 2: Terminal node
 Class      Number  ClassPrior
 0              33     1.00000
 1               0     0.00000
 2               0     0.00000
 Number of training cases misclassified =  0
 Predicted class is 0
 ----------------------------
 Node 3: Intermediate node
 A case goes into Node 6 if PetalLength <=  4.7500000E+00
 PetalLength mean =  4.8742E+00
 Class      Number  ClassPrior
 0               0     0.00000
 1              33     0.50000
 2              33     0.50000
 Number of training cases misclassified =  33
 Predicted class is 1
 ----------------------------
 Node 6: Terminal node
 Class      Number  ClassPrior
 0               0     0.00000
 1              31     0.96875
 2               1     0.03125
 Number of training cases misclassified =  1
 Predicted class is 1
 ----------------------------
 Node 7: Terminal node
 Class      Number  ClassPrior
 0               0     0.00000
 1               2     0.05882
 2              32     0.94118
 Number of training cases misclassified =  2
 Predicted class is 2
 ----------------------------
  
 
 Classification matrix for training sample:
 Predicted      True class
 class              0         1         2
 0                 33         0         0
 1                  0        31         1
 2                  0         2        32
 Total             33        33        33
 
 Number of cases used for tree construction =  99
 Number misclassified =  3
 Resubstitution est. of mean misclassification cost =    3.0303030303030300E-002
 
 Elapsed time in seconds:    1.60000008E-02
